{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1175b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp-scratch ------多层感知机从零实现\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#数据导入\n",
    "batch_size=256\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "#初始化模型参数\n",
    "num_inputs,num_outputs,num_hiddens=784,10,256 #输入，输出，隐藏层隐藏单元\n",
    "W1=nn.Parameter(torch.randn(num_inputs,num_hiddens,requires_grad=True)*0.01) #输入层到隐藏层\n",
    "b1=nn.Parameter(torch.zeros(num_hiddens,require_grad=True))\n",
    "W2=nn.Parameter(torch.randn(num_inputs,num_hiddens,require_grad=True)*0.01) #隐藏层到输出层\n",
    "b2=nn.Parameter(torch.zeros(num_outputs,require_grad=True))\n",
    "\n",
    "params=[W1,b1,W2,b2]\n",
    "\n",
    "#激活函数：实现ReLU函数\n",
    "def relu(X):\n",
    "    a=torch.zeros_like(X)\n",
    "    return torch.max(X,a)\n",
    "\n",
    "#定义模型\n",
    "def net(X):\n",
    "    X=X.reshape((-1,num_inputs)) #将每个二维图像转换为一个长度为num_inputs的向量\n",
    "    H=relu(X@W1+b1) #这里@表示矩阵乘法\n",
    "    return (H@W2+b2)\n",
    "\n",
    "#损失函数\n",
    "loss=nn.CrossEntropyLoss() #使用内置API计算交叉熵损失\n",
    "\n",
    "#训练：与softmax训练过程完全相同\n",
    "num_epochs,lr=10,0.1\n",
    "updater=torch.optim.SGD(params,lr=lr)\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,updater)\n",
    "\n",
    "#模型应用于测试数据\n",
    "d2l.predict_ch3(net,test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp-concise ------多层感知机简洁实现--使用API构建网络\n",
    "import torch\n",
    "feom torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#模型\n",
    "net=nn.Sequential(nn.Flatten(),\n",
    "                 nn.Linear(784,256),\n",
    "                 nn.ReLU().\n",
    "                 nn.Linear(256,10))\n",
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.normal_(m.weight,std=0.01)\n",
    "net.apply(init_weights);\n",
    "\n",
    "#交叉熵损失函数\n",
    "loss=nn.CrossEntropyLoss() \n",
    "\n",
    "#训练\n",
    "batch_size,lr,num_epochs=256,0.1,10\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size) #数据导入\n",
    "trainer=torch.optim.SGD(net.parameters(),lr=lr) #参数优化\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd1d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多项式拟合--模型复杂性\n",
    "import math \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#生成数据\n",
    "max_degree=20 #多项式最大阶数\n",
    "n_train,n_test=100,100 #训练集和测试集大小\n",
    "true_w=np.zeros(max_degree) #分配空间\n",
    "true_w[0:4]=np.array([5,1.2,-3.4,5.6])\n",
    "\n",
    "features=np.random.normal(size=(n_train+ntest,1)) #训练集和测试集均为100x1的正态分布随机数\n",
    "np.random.shuffle(features)\n",
    "poly_features=np.power(features,np.arange(max_degree).reshape(1,-1)) #feature中的数，通过广播机制求每个数的0~19次方，ploy_features.shape=200x20。np.arange(max_degree).reshape(1, -1)将轴数从1调整为2\n",
    "for i in range(max_degree):\n",
    "    poly_features[:,i]/=math.gamma(i,1) #自变量的n次方除以对应阶数n的gamma(n)=(n-1)!\n",
    "labels=np.dot(poly_features,true_w) #各阶数的自变量乘以系数得到输出y。labels维度：(n_train+n_test,)\n",
    "labels+=np.random.normal(scale=0.1,size=labels.shape) #加上噪声\n",
    "true_w,features,poly_features,labels=[torch.tensor(x,dtype=torch.float32) \n",
    "                                     for x in [true_w,features,poly_features,labels]] #numpy ndarray转换为tensor\n",
    "\n",
    "#损失函数\n",
    "def evaluate_loss(net,data_iter,loss): #@save\n",
    "    metric=d2l.Accumulator(2)\n",
    "    for X,y in data_iter:\n",
    "        out=net(X)\n",
    "        y=y.reshape(out.shape)\n",
    "        l=loss(out,y)\n",
    "        metrix.add(l.sum(),l.numel())\n",
    "    return metric[0]/metric[1]\n",
    "\n",
    "#训练函数\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
